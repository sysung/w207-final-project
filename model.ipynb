{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-21 23:54:54.851132: I tensorflow/c/logging.cc:34] Successfully opened dynamic library libdirectml.0de2b4431c6572ee74152a7ee0cd3fb1534e4a95.so\n",
      "2022-07-21 23:54:54.851301: I tensorflow/c/logging.cc:34] Successfully opened dynamic library libdxcore.so\n",
      "2022-07-21 23:54:54.858856: I tensorflow/c/logging.cc:34] Successfully opened dynamic library libd3d12.so\n",
      "2022-07-21 23:54:56.685977: I tensorflow/c/logging.cc:34] DirectML device enumeration: found 1 compatible adapters.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow import keras\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_df_fp = os.path.abspath(\"data/annotations.csv\")\n",
    "annotations_df = pd.read_csv(annotation_df_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create X, Y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_img_loc = annotations_df[\"crop_img_filename\"].apply(lambda x: os.path.abspath(\"data/crop\" + \"/\" + x))\n",
    "crop_imgs = crop_img_loc.apply(load_img).apply(img_to_array)\n",
    "\n",
    "X_data_np = np.stack(crop_imgs)\n",
    "Y_data_np = annotations_df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_data_np.shape:  (1216, 100, 100, 3)\n",
      "Y_data_np.shape:  (1216,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_data_np.shape: \", X_data_np.shape)\n",
    "print(\"Y_data_np.shape: \", Y_data_np.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (729, 100, 100, 3)\n",
      "X_val shape: (243, 100, 100, 3)\n",
      "X_test shape: (244, 100, 100, 3)\n",
      "Y_train shape: (729,)\n",
      "Y_val shape: (243,)\n",
      "Y_test shape: (244,)\n"
     ]
    }
   ],
   "source": [
    "# Split into train, validation, and test split of 0.6/0.2/0.2\n",
    "def split_data(images, y, split=(0.6,0.2,0.2)):\n",
    "    tf.random.set_seed(1234)\n",
    "    np.random.seed(1234)\n",
    "    shuffle = np.random.permutation(np.arange(images.shape[0]))\n",
    "    images, y = images[shuffle], y[shuffle]\n",
    "    \n",
    "    splits = np.multiply(len(images), split).astype(int)\n",
    "    X_train, X_val, X_test = np.split(images, [splits[0], splits[0]+splits[1]])\n",
    "    Y_train, Y_val, Y_test = np.split(y, [splits[0], splits[0]+splits[1]])\n",
    "\n",
    "    return X_train, Y_train, X_val, Y_val, X_test, Y_test\n",
    "\n",
    "X_train, Y_train, X_val, Y_val, X_test, Y_test = split_data(X_data_np, Y_data_np)\n",
    "print(\"X_train shape: \", end='')\n",
    "print(X_train.shape)\n",
    "print(\"X_val shape: \", end='')\n",
    "print(X_val.shape)\n",
    "print(\"X_test shape: \", end='')\n",
    "print(X_test.shape)\n",
    "print(\"Y_train shape: \", end='')\n",
    "print(Y_train.shape)\n",
    "print(\"Y_val shape: \", end='')\n",
    "print(Y_val.shape)\n",
    "print(\"Y_test shape: \", end='')\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create binary classification labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_binary = np.copy(Y_train)\n",
    "Y_val_binary = np.copy(Y_val)\n",
    "Y_test_binary = np.copy(Y_test)\n",
    "\n",
    "# assign \n",
    "# - without_mask = 0\n",
    "# - with_mask = 1\n",
    "Y_train_binary[Y_train_binary == 'without_mask'] = 0.0 \n",
    "Y_train_binary[Y_train_binary == 'with_mask'] = 1.0\n",
    "Y_val_binary[Y_val_binary == 'without_mask'] = 0.0 \n",
    "Y_val_binary[Y_val_binary == 'with_mask'] = 1.0\n",
    "Y_test_binary[Y_test_binary == 'without_mask'] = 0.0\n",
    "Y_test_binary[Y_test_binary == 'with_mask'] = 1.0\n",
    "\n",
    "Y_train_binary = Y_train_binary.astype('float32')\n",
    "Y_val_binary = Y_val_binary.astype('float32')\n",
    "Y_test_binary = Y_test_binary.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the data to achieve some kind of random sampling\n",
    "np.random.seed(0) # For reproducibility\n",
    "\n",
    "indices = np.arange(X_train.shape[0])\n",
    "shuffled_indices = np.random.permutation(indices)\n",
    "\n",
    "# Re-order training examples and corresponding labels using the randomly\n",
    "# shuffled indices.\n",
    "X_train = X_train[shuffled_indices]\n",
    "Y_train_binary = Y_train_binary[shuffled_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sequential_model(learning_rate=0.01):\n",
    "  \"\"\"Build a TF logistic regression model using Keras.\n",
    "\n",
    "  Args:\n",
    "    learning_rate: The desired learning rate for SGD.\n",
    "\n",
    "  Returns:\n",
    "    model: A tf.keras model (graph).\n",
    "  \"\"\"\n",
    "  # This is not strictly necessary, but each time you build a model, TF adds\n",
    "  # new nodes (rather than overwriting), so the colab session can end up\n",
    "  # storing lots of copies of the graph when you only care about the most\n",
    "  # recent. Also, as there is some randomness built into training with SGD,\n",
    "  # setting a random seed ensures that results are the same on each identical\n",
    "  # training run.\n",
    "  tf.keras.backend.clear_session()\n",
    "  np.random.seed(0)\n",
    "  tf.random.set_seed(0)\n",
    "\n",
    "  # Build a model using keras.Sequential.\n",
    "  model = keras.Sequential()\n",
    "\n",
    "  # Flatten (100x100) input to a flat array\n",
    "  model.add(keras.layers.Flatten())\n",
    "  \n",
    "  # This layer constructs the linear set of parameters for each input feature\n",
    "  # (as well as a bias), and applies a sigmoid to the result. The result is\n",
    "  # binary logistic regression.\n",
    "  model.add(keras.layers.Dense(\n",
    "      units=1,                     # output dim (for binary classification)\n",
    "      use_bias=True,               # use a bias param\n",
    "      activation=\"sigmoid\"         # apply the sigmoid function!\n",
    "  ))\n",
    "\n",
    "  # Use the SGD optimizer as usual.\n",
    "  optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "  # We specify the binary_crossentropy loss (equivalent to log loss).\n",
    "  # Notice that we are including 'binary accuracy' as one of the metrics that we\n",
    "  # ask Tensorflow to report when evaluating the model.\n",
    "  model.compile(loss='binary_crossentropy', \n",
    "                optimizer=optimizer, \n",
    "                metrics=[metrics.binary_accuracy])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-21 23:55:44.129167: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-21 23:55:44.130070: I tensorflow/c/logging.cc:34] DirectML: creating device on adapter 0 (NVIDIA GeForce RTX 2070 with Max-Q Design)\n",
      "2022-07-21 23:55:44.953631: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-07-21 23:55:44.953667: W tensorflow/core/common_runtime/pluggable_device/pluggable_device_bfc_allocator.cc:28] Overriding allow_growth setting because force_memory_growth was requested by the device.\n",
      "2022-07-21 23:55:44.953686: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6827 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "X_train_tensor = tf.convert_to_tensor(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-21 23:56:01.633167: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 3s 124ms/step - loss: 461116.6562 - binary_accuracy: 0.5061 - val_loss: 378450.4375 - val_binary_accuracy: 0.4932\n",
      "Epoch 2/5\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 246469.6562 - binary_accuracy: 0.5716 - val_loss: 136279.9375 - val_binary_accuracy: 0.6986\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-21 23:56:03.790754: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 15ms/step - loss: 132926.7344 - binary_accuracy: 0.7256 - val_loss: 44748.0156 - val_binary_accuracy: 0.8219\n",
      "Epoch 4/5\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 33989.5234 - binary_accuracy: 0.8796 - val_loss: 17100.0586 - val_binary_accuracy: 0.9315\n",
      "Epoch 5/5\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 12866.9844 - binary_accuracy: 0.9101 - val_loss: 8769.0273 - val_binary_accuracy: 0.9041\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>binary_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_binary_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>461116.656250</td>\n",
       "      <td>0.506098</td>\n",
       "      <td>378450.437500</td>\n",
       "      <td>0.493151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>246469.656250</td>\n",
       "      <td>0.571646</td>\n",
       "      <td>136279.937500</td>\n",
       "      <td>0.698630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132926.734375</td>\n",
       "      <td>0.725610</td>\n",
       "      <td>44748.015625</td>\n",
       "      <td>0.821918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33989.523438</td>\n",
       "      <td>0.879573</td>\n",
       "      <td>17100.058594</td>\n",
       "      <td>0.931507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12866.984375</td>\n",
       "      <td>0.910061</td>\n",
       "      <td>8769.027344</td>\n",
       "      <td>0.904110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            loss  binary_accuracy       val_loss  val_binary_accuracy\n",
       "0  461116.656250         0.506098  378450.437500             0.493151\n",
       "1  246469.656250         0.571646  136279.937500             0.698630\n",
       "2  132926.734375         0.725610   44748.015625             0.821918\n",
       "3   33989.523438         0.879573   17100.058594             0.931507\n",
       "4   12866.984375         0.910061    8769.027344             0.904110"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build the model.\n",
    "sequential_model = build_sequential_model()\n",
    "\n",
    "history = sequential_model.fit(\n",
    "  x = X_train,   # our binary training examples\n",
    "  y = Y_train_binary,   # corresponding binary labels\n",
    "  epochs=5,             # number of passes through the training data\n",
    "  batch_size=64,        # mini-batch size for SGD\n",
    "  validation_split=0.1, # use a fraction of the examples for validation\n",
    "  verbose=1             # display some progress output during training\n",
    ")\n",
    "\n",
    "# Convert the return value into a DataFrame so we can see the train loss \n",
    "# and binary accuracy after every epoch.\n",
    "history = pd.DataFrame(history.history)\n",
    "display(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Evaluation Metrics](https://towardsdatascience.com/metrics-to-evaluate-your-machine-learning-algorithm-f10ba6e38234)\n",
    "- Explain what each metric does and how it is useful\n",
    "\n",
    "\n",
    "1. [Classification Accuracy](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Accuracy)\n",
    "\n",
    "    Usage with `compile() API`\n",
    "\n",
    "    ```python\n",
    "    model.compile(optimizer=..., loss=..., metrics=[tf.keras.metrics.Accuracy()])\n",
    "    ```\n",
    "2. [Binary Cross Entropy Loss](https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy)\n",
    "\n",
    "    ```python\n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), ...)\n",
    "    ```\n",
    "\n",
    "3. [Confusion Matrix](https://www.tensorflow.org/api_docs/python/tf/math/confusion_matrix)\n",
    "\n",
    "    ```python\n",
    "    tf.math.confusion_matrix(\n",
    "        labels,\n",
    "        predictions,\n",
    "        num_classes=None,\n",
    "        weights=None,\n",
    "        dtype=tf.dtypes.int32,\n",
    "        name=None\n",
    "    )\n",
    "    ```\n",
    "    - Need to get labels and predictions from model\n",
    "\n",
    "4. AUC\n",
    "\n",
    "5. F1 Score\n",
    "\n",
    "6. MSE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f297af12f0f10aff2eb062a4b586522f445c09530fc5b64ba2149c29b9e4e7c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
